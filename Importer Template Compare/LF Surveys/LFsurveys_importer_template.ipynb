{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare NIS Importer Template with Country Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: datacompy in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ebradfield\\appdata\\roaming\\python\\python312\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: ordered-set<=4.1.0,>=4.0.2 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datacompy->-r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: fugue<=0.9.1,>=0.8.7 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datacompy->-r requirements.txt (line 4)) (0.9.1)\n",
      "Requirement already satisfied: polars<=1.7.0,>=0.20.4 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datacompy->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: triad>=0.9.7 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (0.9.8)\n",
      "Requirement already satisfied: adagio>=0.2.4 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ebradfield\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from triad>=0.9.7->fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (17.0.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from triad>=0.9.7->fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (2024.9.0)\n",
      "Requirement already satisfied: fs in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from triad>=0.9.7->fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (2.4.16)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fs->triad>=0.9.7->fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ebradfield\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fs->triad>=0.9.7->fugue<=0.9.1,>=0.8.7->datacompy->-r requirements.txt (line 4)) (75.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Macros and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebradfield\\AppData\\Local\\Temp\\ipykernel_27548\\2402674918.py:7: UserWarning: Python 3.12 and above currently is not supported by Spark and Ray. Please note that some functionality will not work and currently is not supported.\n",
      "  import datacompy\n"
     ]
    }
   ],
   "source": [
    "nis_download = r\"C:\\Users\\ebradfield\\OneDrive - Research Triangle Institute\\Act East\\Country Support\\Uganda\\EAST 56 - FY24 SAR2 Data Updates\\redownload confirmation\\MDA_20241012.xlsx\"\n",
    "country_download = r\"C:\\Users\\ebradfield\\OneDrive - Research Triangle Institute\\Act East\\Country Support\\Uganda\\EAST 56 - FY24 SAR2 Data Updates\\redownload confirmation\\MDA - 2024-10-17T020008.366_postSCHSTHupdates.xlsx\"\n",
    "summary_output= r\"C:\\Users\\ebradfield\\OneDrive - Research Triangle Institute\\Act East\\Country Support\\Uganda\\EAST 56 - FY24 SAR2 Data Updates\\qc\\SCHSTH_MDAcompare__20241017.txt\"\n",
    "additions_deletions = r\"C:\\Users\\ebradfield\\OneDrive - Research Triangle Institute\\Act East\\Country Support\\Uganda\\EAST 56 - FY24 SAR2 Data Updates\\qc\\SCHSTH_MDAcompare_Additions_Deletions_20241017.xlsx\"\n",
    "\n",
    "import pandas as pd \n",
    "import datacompy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Recently Downloaded Importer Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Event UID Organisation Unit*  Event Date Latitude Longitude     Status  \\\n",
      "1    MlqXe62IN8A         Bundibugyo  2023-10-01      NaN       NaN     ACTIVE   \n",
      "2    V0m666Y2CCz            Kayunga  2023-10-01      NaN       NaN     ACTIVE   \n",
      "3    e8xYsUvTtRI             Kagadi  2023-10-01      NaN       NaN     ACTIVE   \n",
      "4    HlGQqMBGxLO              Pader  2023-10-01      NaN       NaN  COMPLETED   \n",
      "5    yd6kqUHLIkx              Pader  2023-10-01      NaN       NaN     ACTIVE   \n",
      "..           ...                ...         ...      ...       ...        ...   \n",
      "109  OdJKLB8ok6I              Omoro  2023-10-01      NaN       NaN     ACTIVE   \n",
      "110  rLHMXgHJc7G              Omoro  2023-10-01      NaN       NaN  COMPLETED   \n",
      "111  Gl7O31QAUhF            Kyotera  2023-10-01      NaN       NaN     ACTIVE   \n",
      "112  hbZC6yifeu5           Kabarole  2023-10-01      NaN       NaN     ACTIVE   \n",
      "113  LSvQyPhQnPx            Sironko  2023-10-01      NaN       NaN     ACTIVE   \n",
      "\n",
      "    Review status MDA start date* Treatment end date of MDA    FY  ...  \\\n",
      "1        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "2        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "3        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "4        Reviewed      2023-10-01                2023-11-30  2024  ...   \n",
      "5        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "..            ...             ...                       ...   ...  ...   \n",
      "109      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "110      Reviewed      2023-10-01                2023-11-30  2024  ...   \n",
      "111      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "112      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "113      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "\n",
      "    Calculated: Total Treatments provided of SAC  \\\n",
      "1                                            NaN   \n",
      "2                                            NaN   \n",
      "3                                            NaN   \n",
      "4                                            NaN   \n",
      "5                                            NaN   \n",
      "..                                           ...   \n",
      "109                                          NaN   \n",
      "110                                          NaN   \n",
      "111                                          NaN   \n",
      "112                                          NaN   \n",
      "113                                          NaN   \n",
      "\n",
      "    Program coverage of SAC for SCH (%) Program coverage of SAC for STH (%)  \\\n",
      "1                                   NaN                                 NaN   \n",
      "2                                   NaN                                 NaN   \n",
      "3                                   NaN                                 NaN   \n",
      "4                                   NaN                                 NaN   \n",
      "5                                   NaN                                 NaN   \n",
      "..                                  ...                                 ...   \n",
      "109                                 NaN                                 NaN   \n",
      "110                                 NaN                                 NaN   \n",
      "111                                 NaN                                 NaN   \n",
      "112                                 NaN                                 NaN   \n",
      "113                                 NaN                                 NaN   \n",
      "\n",
      "    Program coverage of LF MDA (%) Program coverage of TR MDA (%)  \\\n",
      "1                              NaN                            NaN   \n",
      "2                              NaN                            NaN   \n",
      "3                              NaN                            NaN   \n",
      "4                              NaN                            NaN   \n",
      "5                              NaN                            NaN   \n",
      "..                             ...                            ...   \n",
      "109                            NaN                            NaN   \n",
      "110                            NaN                            NaN   \n",
      "111                            NaN                            NaN   \n",
      "112                            NaN                            NaN   \n",
      "113                            NaN                            NaN   \n",
      "\n",
      "    Program coverage of OV MDA (%) Program coverage of SCH MDA (%)  \\\n",
      "1                              NaN                             NaN   \n",
      "2                              NaN                             NaN   \n",
      "3                              NaN                             NaN   \n",
      "4                            97.65                             NaN   \n",
      "5                              NaN                             NaN   \n",
      "..                             ...                             ...   \n",
      "109                            NaN                             NaN   \n",
      "110                          96.27                             NaN   \n",
      "111                            NaN                             NaN   \n",
      "112                            NaN                             NaN   \n",
      "113                            NaN                             NaN   \n",
      "\n",
      "    Program coverage of STH MDA (%)  \\\n",
      "1                               NaN   \n",
      "2                               NaN   \n",
      "3                               NaN   \n",
      "4                               NaN   \n",
      "5                               NaN   \n",
      "..                              ...   \n",
      "109                             NaN   \n",
      "110                             NaN   \n",
      "111                             NaN   \n",
      "112                             NaN   \n",
      "113                             NaN   \n",
      "\n",
      "    District treated for LF and OV with USAID funding  \\\n",
      "1                                                 NaN   \n",
      "2                                                 NaN   \n",
      "3                                                 NaN   \n",
      "4                                                 NaN   \n",
      "5                                                 NaN   \n",
      "..                                                ...   \n",
      "109                                               NaN   \n",
      "110                                               NaN   \n",
      "111                                               NaN   \n",
      "112                                               NaN   \n",
      "113                                               NaN   \n",
      "\n",
      "    District treated for LF and STH with USAID funding  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "5                                                  NaN  \n",
      "..                                                 ...  \n",
      "109                                                NaN  \n",
      "110                                                NaN  \n",
      "111                                                NaN  \n",
      "112                                                NaN  \n",
      "113                                                NaN  \n",
      "\n",
      "[113 rows x 213 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from_nis = pd.read_excel(io=f'{nis_download}', sheet_name =\"Data\", skiprows = 1)\n",
    "from_nis.columns.values[0] = \"Event UID\"\n",
    "from_nis.columns.values[1] = 'Organisation Unit*'\n",
    "from_nis.columns.values[2] = 'Event Date'\n",
    "from_nis.columns.values[3] = 'Latitude'\n",
    "from_nis.columns.values[4] = 'Longitude'\n",
    "from_nis.columns.values[5] = 'Status'\n",
    "from_nis.drop(0, inplace=True)\n",
    "print(from_nis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Summary of Recently Downloaded Importer Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event UID                                             113\n",
       "Organisation Unit*                                     93\n",
       "Event Date                                              2\n",
       "Latitude                                                0\n",
       "Longitude                                               0\n",
       "                                                     ... \n",
       "Program coverage of OV MDA (%)                         19\n",
       "Program coverage of SCH MDA (%)                         5\n",
       "Program coverage of STH MDA (%)                         4\n",
       "District treated for LF and OV with USAID funding       0\n",
       "District treated for LF and STH with USAID funding      0\n",
       "Length: 213, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_nis.nunique(axis=0, dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Template from Country Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Event UID Organisation Unit*  Event Date Latitude Longitude     Status  \\\n",
      "1    MlqXe62IN8A         Bundibugyo  2023-10-01      NaN       NaN  COMPLETED   \n",
      "2    V0m666Y2CCz            Kayunga  2023-10-01      NaN       NaN  COMPLETED   \n",
      "3    e8xYsUvTtRI             Kagadi  2023-10-01      NaN       NaN  COMPLETED   \n",
      "4    HlGQqMBGxLO              Pader  2023-10-01      NaN       NaN  COMPLETED   \n",
      "5    yd6kqUHLIkx              Pader  2023-10-01      NaN       NaN  COMPLETED   \n",
      "..           ...                ...         ...      ...       ...        ...   \n",
      "109  OdJKLB8ok6I              Omoro  2023-10-01      NaN       NaN  COMPLETED   \n",
      "110  rLHMXgHJc7G              Omoro  2023-10-01      NaN       NaN  COMPLETED   \n",
      "111  Gl7O31QAUhF            Kyotera  2023-10-01      NaN       NaN  COMPLETED   \n",
      "112  hbZC6yifeu5           Kabarole  2023-10-01      NaN       NaN  COMPLETED   \n",
      "113  LSvQyPhQnPx            Sironko  2023-10-01      NaN       NaN  COMPLETED   \n",
      "\n",
      "    Review status MDA start date* Treatment end date of MDA    FY  ...  \\\n",
      "1        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "2        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "3        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "4        Reviewed      2023-10-01                2023-11-30  2024  ...   \n",
      "5        Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "..            ...             ...                       ...   ...  ...   \n",
      "109      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "110      Reviewed      2023-10-01                2023-11-30  2024  ...   \n",
      "111      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "112      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "113      Reviewed      2024-04-01                2024-08-01  2024  ...   \n",
      "\n",
      "    Calculated: Total Treatments provided of SAC  \\\n",
      "1                                            NaN   \n",
      "2                                            NaN   \n",
      "3                                            NaN   \n",
      "4                                            NaN   \n",
      "5                                            NaN   \n",
      "..                                           ...   \n",
      "109                                          NaN   \n",
      "110                                          NaN   \n",
      "111                                          NaN   \n",
      "112                                          NaN   \n",
      "113                                          NaN   \n",
      "\n",
      "    Program coverage of SAC for SCH (%) Program coverage of SAC for STH (%)  \\\n",
      "1                                   NaN                                 NaN   \n",
      "2                                   NaN                                 NaN   \n",
      "3                                   NaN                                 NaN   \n",
      "4                                   NaN                                 NaN   \n",
      "5                                   NaN                                 NaN   \n",
      "..                                  ...                                 ...   \n",
      "109                                 NaN                                 NaN   \n",
      "110                                 NaN                                 NaN   \n",
      "111                                 NaN                                 NaN   \n",
      "112                                 NaN                                 NaN   \n",
      "113                                 NaN                                 NaN   \n",
      "\n",
      "    Program coverage of LF MDA (%) Program coverage of TR MDA (%)  \\\n",
      "1                              NaN                            NaN   \n",
      "2                              NaN                            NaN   \n",
      "3                              NaN                            NaN   \n",
      "4                              NaN                            NaN   \n",
      "5                              NaN                            NaN   \n",
      "..                             ...                            ...   \n",
      "109                            NaN                            NaN   \n",
      "110                            NaN                            NaN   \n",
      "111                            NaN                            NaN   \n",
      "112                            NaN                            NaN   \n",
      "113                            NaN                            NaN   \n",
      "\n",
      "    Program coverage of OV MDA (%) Program coverage of SCH MDA (%)  \\\n",
      "1                              NaN                             NaN   \n",
      "2                              NaN                             NaN   \n",
      "3                              NaN                             NaN   \n",
      "4                            97.65                             NaN   \n",
      "5                              NaN                             NaN   \n",
      "..                             ...                             ...   \n",
      "109                            NaN                             NaN   \n",
      "110                          96.27                             NaN   \n",
      "111                            NaN                             NaN   \n",
      "112                            NaN                             NaN   \n",
      "113                            NaN                             NaN   \n",
      "\n",
      "    Program coverage of STH MDA (%)  \\\n",
      "1                               NaN   \n",
      "2                               NaN   \n",
      "3                               NaN   \n",
      "4                               NaN   \n",
      "5                               NaN   \n",
      "..                              ...   \n",
      "109                             NaN   \n",
      "110                             NaN   \n",
      "111                             NaN   \n",
      "112                             NaN   \n",
      "113                             NaN   \n",
      "\n",
      "    District treated for LF and OV with USAID funding  \\\n",
      "1                                                 NaN   \n",
      "2                                                 NaN   \n",
      "3                                                 NaN   \n",
      "4                                                 NaN   \n",
      "5                                                 NaN   \n",
      "..                                                ...   \n",
      "109                                               NaN   \n",
      "110                                               NaN   \n",
      "111                                               NaN   \n",
      "112                                               NaN   \n",
      "113                                               NaN   \n",
      "\n",
      "    District treated for LF and STH with USAID funding  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "5                                                  NaN  \n",
      "..                                                 ...  \n",
      "109                                                NaN  \n",
      "110                                                NaN  \n",
      "111                                                NaN  \n",
      "112                                                NaN  \n",
      "113                                                NaN  \n",
      "\n",
      "[113 rows x 213 columns]\n"
     ]
    }
   ],
   "source": [
    "from_country = pd.read_excel(io=f'{country_download}', sheet_name =\"Data\", skiprows = 1)\n",
    "from_country.columns.values[0] = \"Event UID\"\n",
    "from_country.columns.values[1] = 'Organisation Unit*'\n",
    "from_country.columns.values[2] = 'Event Date'\n",
    "from_country.columns.values[3] = 'Latitude'\n",
    "from_country.columns.values[4] = 'Longitude'\n",
    "from_country.columns.values[5] = 'Status'\n",
    "from_country.drop(0, inplace=True)\n",
    "print(from_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Summary of Template from Country Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event UID                                             113\n",
       "Organisation Unit*                                     93\n",
       "Event Date                                              2\n",
       "Latitude                                                0\n",
       "Longitude                                               0\n",
       "                                                     ... \n",
       "Program coverage of OV MDA (%)                         19\n",
       "Program coverage of SCH MDA (%)                         5\n",
       "Program coverage of STH MDA (%)                         4\n",
       "District treated for LF and OV with USAID funding       0\n",
       "District treated for LF and STH with USAID funding      0\n",
       "Length: 213, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_country.nunique(axis=0, dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframes and Identify Discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n",
      "c:\\Users\\ebradfield\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datacompy\\core.py:351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.intersect_rows[col_match] = columns_equal(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "      DataFrame  Columns  Rows\n",
      "0      from_nis      213   113\n",
      "1  from_country      213   113\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 213\n",
      "Number of columns in from_nis but not in from_country: 0\n",
      "Number of columns in from_country but not in from_nis: 0\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: organisation unit*\n",
      "Any duplicates on match values: Yes\n",
      "Absolute Tolerance: 0\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 113\n",
      "Number of rows in from_nis but not in from_country: 0\n",
      "Number of rows in from_country but not in from_nis: 0\n",
      "\n",
      "Number of rows with some compared columns unequal: 90\n",
      "Number of rows with all compared columns equal: 23\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 19\n",
      "Number of columns compared with all values equal: 194\n",
      "Total number of values which compare unequal: 110\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "                                                          Column from_nis dtype from_country dtype  # Unequal     Max Diff  # Null Diff\n",
      "13  calculated: program coverage of sac across diseases selected         object             object          1     0.363539            0\n",
      "14                         calculated: total treatments provided         object             object          1  1608.000000            0\n",
      "15                 calculated: total treatments provided of psac         object             object          1     0.000000            1\n",
      "16                  calculated: total treatments provided of sac         object             object          1   502.000000            0\n",
      "4                                                   mda comments         object             object          5     0.000000            5\n",
      "17                           program coverage of sac for sch (%)         object             object          1     0.360000            0\n",
      "18                               program coverage of sth mda (%)         object             object          1     2.750000            0\n",
      "12                                    sch- number of sac treated         object             object          1   502.000000            0\n",
      "0                                                         status         object             object         85     0.000000            0\n",
      "6                                 sth- number of females treated         object             object          1     0.000000            1\n",
      "10                                    sth- number of hra treated         object             object          1     0.000000            1\n",
      "7                                   sth- number of males treated         object             object          1     0.000000            1\n",
      "5                                 sth- number of persons treated         object             object          2  1608.000000            1\n",
      "8                                    sth- number of psac treated         object             object          1     0.000000            1\n",
      "9                                     sth- number of sac treated         object             object          1     0.000000            1\n",
      "11                                    sth- number of wra treated         object             object          3     0.000000            3\n",
      "2                                           usaid funding source         object             object          1     0.000000            1\n",
      "3                        usaid supported implementing partner #1         object             object          1     0.000000            1\n",
      "1                                                  usaid-funded?         object             object          1     0.000000            0\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "         organisation unit* status (from_nis) status (from_country)\n",
      "0                   Buyende            ACTIVE             COMPLETED\n",
      "1                   Manafwa            ACTIVE             COMPLETED\n",
      "2                  Kassanda            ACTIVE             COMPLETED\n",
      "3                   Mubende            ACTIVE             COMPLETED\n",
      "4                    Kitgum            ACTIVE             COMPLETED\n",
      "5                 Bulambuli            ACTIVE             COMPLETED\n",
      "6                      Oyam            ACTIVE             COMPLETED\n",
      "7                    Mayuge            ACTIVE             COMPLETED\n",
      "8                      Apac            ACTIVE             COMPLETED\n",
      "9                   Bugweri            ACTIVE             COMPLETED\n",
      "10                 Rubirizi            ACTIVE             COMPLETED\n",
      "11                   Kibuku            ACTIVE             COMPLETED\n",
      "12                   Terego            ACTIVE             COMPLETED\n",
      "13                    Mpigi            ACTIVE             COMPLETED\n",
      "14                   Kasese            ACTIVE             COMPLETED\n",
      "15                    Omoro            ACTIVE             COMPLETED\n",
      "16                    Zombo            ACTIVE             COMPLETED\n",
      "17                    Kween            ACTIVE             COMPLETED\n",
      "18                   Buikwe            ACTIVE             COMPLETED\n",
      "19                 Alebtong            ACTIVE             COMPLETED\n",
      "20            Nakapiripirit            ACTIVE             COMPLETED\n",
      "21              Kaberamaido            ACTIVE             COMPLETED\n",
      "22  Ibanda (Western Region)            ACTIVE             COMPLETED\n",
      "23                   Kaliro            ACTIVE             COMPLETED\n",
      "24                     Lira            ACTIVE             COMPLETED\n",
      "25                   Butebo            ACTIVE             COMPLETED\n",
      "26                    Pader            ACTIVE             COMPLETED\n",
      "27                  Kalungu            ACTIVE             COMPLETED\n",
      "28                    Nwoya            ACTIVE             COMPLETED\n",
      "29                    Luuka            ACTIVE             COMPLETED\n",
      "30                    Gomba            ACTIVE             COMPLETED\n",
      "31                  Bukedea            ACTIVE             COMPLETED\n",
      "32                 Kabarole            ACTIVE             COMPLETED\n",
      "33                  Pallisa            ACTIVE             COMPLETED\n",
      "34                   Mukono            ACTIVE             COMPLETED\n",
      "35                Kalangala            ACTIVE             COMPLETED\n",
      "36                    Jinja            ACTIVE             COMPLETED\n",
      "37                 Adjumani            ACTIVE             COMPLETED\n",
      "38              Nakasongola            ACTIVE             COMPLETED\n",
      "39                 Amolatar            ACTIVE             COMPLETED\n",
      "40                   Bugiri            ACTIVE             COMPLETED\n",
      "41                   Obongi            ACTIVE             COMPLETED\n",
      "42                   Dokolo            ACTIVE             COMPLETED\n",
      "43                   Buvuma            ACTIVE             COMPLETED\n",
      "44                   Budaka            ACTIVE             COMPLETED\n",
      "45                     Kazo            ACTIVE             COMPLETED\n",
      "46                Namutumba            ACTIVE             COMPLETED\n",
      "47               Jinja City            ACTIVE             COMPLETED\n",
      "48                Insingiro            ACTIVE             COMPLETED\n",
      "49                   Soroti            ACTIVE             COMPLETED\n",
      "50                  Katakwi            ACTIVE             COMPLETED\n",
      "51                Arua City            ACTIVE             COMPLETED\n",
      "52               Bundibugyo            ACTIVE             COMPLETED\n",
      "53                    Lamwo            ACTIVE             COMPLETED\n",
      "54                   Kwania            ACTIVE             COMPLETED\n",
      "55                     Gulu            ACTIVE             COMPLETED\n",
      "56                     Arua            ACTIVE             COMPLETED\n",
      "57                  Kyotera            ACTIVE             COMPLETED\n",
      "58                   Masaka            ACTIVE             COMPLETED\n",
      "59               Bunyangabu            ACTIVE             COMPLETED\n",
      "60                  Kayunga            ACTIVE             COMPLETED\n",
      "61               Namisindwa            ACTIVE             COMPLETED\n",
      "62                Namayingo            ACTIVE             COMPLETED\n",
      "63                   Tororo            ACTIVE             COMPLETED\n",
      "64                  Mityana            ACTIVE             COMPLETED\n",
      "65                 Butaleja            ACTIVE             COMPLETED\n",
      "66                   Kalaki            ACTIVE             COMPLETED\n",
      "67                    Rakai            ACTIVE             COMPLETED\n",
      "68                   Kamuli            ACTIVE             COMPLETED\n",
      "69               Kitagwenda            ACTIVE             COMPLETED\n",
      "70                   Kagadi            ACTIVE             COMPLETED\n",
      "71                  Sironko            ACTIVE             COMPLETED\n",
      "72              Kiryandongo            ACTIVE             COMPLETED\n",
      "73                   Wakiso            ACTIVE             COMPLETED\n",
      "74                    Yumbe            ACTIVE             COMPLETED\n",
      "75                    Ngora            ACTIVE             COMPLETED\n",
      "76              Madi Okollo            ACTIVE             COMPLETED\n",
      "77                   Iganga            ACTIVE             COMPLETED\n",
      "78                     Moyo            ACTIVE             COMPLETED\n",
      "79                   Koboko            ACTIVE             COMPLETED\n",
      "80                   Serere            ACTIVE             COMPLETED\n",
      "81                    Busia            ACTIVE             COMPLETED\n",
      "82                    Mbale            ACTIVE             COMPLETED\n",
      "83               Mbale City            ACTIVE             COMPLETED\n",
      "84  Amuru (Northern Region)            ACTIVE             COMPLETED\n",
      "\n",
      "  organisation unit* usaid-funded? (from_nis) usaid-funded? (from_country)\n",
      "0             Buikwe                    USAID                    Non-USAID\n",
      "\n",
      "  organisation unit* usaid funding source (from_nis) usaid funding source (from_country)\n",
      "0             Buikwe                      Act | East                                 NaN\n",
      "\n",
      "  organisation unit* usaid supported implementing partner #1 (from_nis) usaid supported implementing partner #1 (from_country)\n",
      "0             Buikwe                                                RTI                                                    NaN\n",
      "\n",
      "  organisation unit* mda comments (from_nis)                                                 mda comments (from_country)\n",
      "0            Kikuube                     NaN  HRA were not initially targeted for SCH, but MOH later approved treatment.\n",
      "1            Buliisa                     NaN  HRA were not initially targeted for SCH, but MOH later approved treatment.\n",
      "2            Pakwach                     NaN  HRA were not initially targeted for SCH, but MOH later approved treatment.\n",
      "3            Ntoroko                     NaN  HRA were not initially targeted for SCH, but MOH later approved treatment.\n",
      "4            Maracha                     NaN  HRA were not initially targeted for SCH, but MOH later approved treatment.\n",
      "\n",
      "  organisation unit* sth- number of persons treated (from_nis) sth- number of persons treated (from_country)\n",
      "0            Kikuube                                       NaN                                             0\n",
      "1            Buliisa                                     42196                                         43804\n",
      "\n",
      "  organisation unit* sth- number of females treated (from_nis) sth- number of females treated (from_country)\n",
      "0            Kikuube                                       NaN                                             0\n",
      "\n",
      "  organisation unit* sth- number of males treated (from_nis) sth- number of males treated (from_country)\n",
      "0            Kikuube                                     NaN                                           0\n",
      "\n",
      "  organisation unit* sth- number of psac treated (from_nis) sth- number of psac treated (from_country)\n",
      "0            Kikuube                                    NaN                                          0\n",
      "\n",
      "  organisation unit* sth- number of sac treated (from_nis) sth- number of sac treated (from_country)\n",
      "0            Kikuube                                   NaN                                         0\n",
      "\n",
      "  organisation unit* sth- number of hra treated (from_nis) sth- number of hra treated (from_country)\n",
      "0            Kikuube                                   NaN                                         0\n",
      "\n",
      "  organisation unit* sth- number of wra treated (from_nis) sth- number of wra treated (from_country)\n",
      "0            Buliisa                                   NaN                                         0\n",
      "1            Kikuube                                   NaN                                         0\n",
      "2            Pakwach                                   NaN                                         0\n",
      "\n",
      "  organisation unit* sch- number of sac treated (from_nis) sch- number of sac treated (from_country)\n",
      "0            Kikuube                                 64068                                     64570\n",
      "\n",
      "  organisation unit* calculated: program coverage of sac across diseases selected (from_nis) calculated: program coverage of sac across diseases selected (from_country)\n",
      "0            Kikuube                                                               46.396837                                                                   46.760376\n",
      "\n",
      "  organisation unit* calculated: total treatments provided (from_nis) calculated: total treatments provided (from_country)\n",
      "0            Buliisa                                           102742                                               104350\n",
      "\n",
      "  organisation unit* calculated: total treatments provided of psac (from_nis) calculated: total treatments provided of psac (from_country)\n",
      "0            Kikuube                                                      NaN                                                            0\n",
      "\n",
      "  organisation unit* calculated: total treatments provided of sac (from_nis) calculated: total treatments provided of sac (from_country)\n",
      "0            Kikuube                                                   64068                                                       64570\n",
      "\n",
      "  organisation unit* program coverage of sac for sch (%) (from_nis) program coverage of sac for sch (%) (from_country)\n",
      "0            Kikuube                                           46.4                                              46.76\n",
      "\n",
      "  organisation unit* program coverage of sth mda (%) (from_nis) program coverage of sth mda (%) (from_country)\n",
      "0            Buliisa                                      72.15                                           74.9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare = datacompy.Compare(from_nis, from_country, join_columns=['Organisation Unit*'], df1_name='from_nis',\n",
    "    df2_name='from_country')\n",
    "\n",
    "print(compare.report(sample_count=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Summary File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          organisation unit* event uid_from_nis event uid_from_country  \\\n",
      "1                   Adjumani        XseIhc8pWhu            XseIhc8pWhu   \n",
      "3                   Alebtong        ktnf66EUbOz            ktnf66EUbOz   \n",
      "4                   Amolatar        WUtbb0adJF8            WUtbb0adJF8   \n",
      "5    Amuru (Northern Region)        hKfxj9XoA87            hKfxj9XoA87   \n",
      "8                       Apac        LAvd43cUgy9            LAvd43cUgy9   \n",
      "..                       ...                ...                    ...   \n",
      "108                   Terego        LOiMO9KDtTC            LOiMO9KDtTC   \n",
      "109                   Tororo        fvSpjNYnM1b            fvSpjNYnM1b   \n",
      "110                   Wakiso        C3v7GCORDdW            C3v7GCORDdW   \n",
      "111                    Yumbe        n1zb0SPeG7z            n1zb0SPeG7z   \n",
      "112                    Zombo        dlbDDf0UtDU            dlbDDf0UtDU   \n",
      "\n",
      "    event date_from_nis event date_from_country latitude_from_nis  \\\n",
      "1            2023-10-01              2023-10-01               NaN   \n",
      "3            2023-10-01              2023-10-01               NaN   \n",
      "4            2023-10-01              2023-10-01               NaN   \n",
      "5            2023-10-01              2023-10-01               NaN   \n",
      "8            2023-10-01              2023-10-01               NaN   \n",
      "..                  ...                     ...               ...   \n",
      "108          2023-10-01              2023-10-01               NaN   \n",
      "109          2023-10-01              2023-10-01               NaN   \n",
      "110          2023-10-01              2023-10-01               NaN   \n",
      "111          2023-10-01              2023-10-01               NaN   \n",
      "112          2023-10-01              2023-10-01               NaN   \n",
      "\n",
      "    latitude_from_country longitude_from_nis longitude_from_country  \\\n",
      "1                     NaN                NaN                    NaN   \n",
      "3                     NaN                NaN                    NaN   \n",
      "4                     NaN                NaN                    NaN   \n",
      "5                     NaN                NaN                    NaN   \n",
      "8                     NaN                NaN                    NaN   \n",
      "..                    ...                ...                    ...   \n",
      "108                   NaN                NaN                    NaN   \n",
      "109                   NaN                NaN                    NaN   \n",
      "110                   NaN                NaN                    NaN   \n",
      "111                   NaN                NaN                    NaN   \n",
      "112                   NaN                NaN                    NaN   \n",
      "\n",
      "    status_from_nis  ... program coverage of ov mda (%)_from_nis  \\\n",
      "1            ACTIVE  ...                                     NaN   \n",
      "3            ACTIVE  ...                                     NaN   \n",
      "4            ACTIVE  ...                                     NaN   \n",
      "5            ACTIVE  ...                                     NaN   \n",
      "8            ACTIVE  ...                                     NaN   \n",
      "..              ...  ...                                     ...   \n",
      "108          ACTIVE  ...                                     NaN   \n",
      "109          ACTIVE  ...                                     NaN   \n",
      "110          ACTIVE  ...                                     NaN   \n",
      "111          ACTIVE  ...                                     NaN   \n",
      "112          ACTIVE  ...                                     NaN   \n",
      "\n",
      "    program coverage of ov mda (%)_from_country  \\\n",
      "1                                           NaN   \n",
      "3                                           NaN   \n",
      "4                                           NaN   \n",
      "5                                           NaN   \n",
      "8                                           NaN   \n",
      "..                                          ...   \n",
      "108                                         NaN   \n",
      "109                                         NaN   \n",
      "110                                         NaN   \n",
      "111                                         NaN   \n",
      "112                                         NaN   \n",
      "\n",
      "    program coverage of sch mda (%)_from_nis  \\\n",
      "1                                        NaN   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "5                                        NaN   \n",
      "8                                        NaN   \n",
      "..                                       ...   \n",
      "108                                      NaN   \n",
      "109                                      NaN   \n",
      "110                                      NaN   \n",
      "111                                      NaN   \n",
      "112                                      NaN   \n",
      "\n",
      "    program coverage of sch mda (%)_from_country  \\\n",
      "1                                            NaN   \n",
      "3                                            NaN   \n",
      "4                                            NaN   \n",
      "5                                            NaN   \n",
      "8                                            NaN   \n",
      "..                                           ...   \n",
      "108                                          NaN   \n",
      "109                                          NaN   \n",
      "110                                          NaN   \n",
      "111                                          NaN   \n",
      "112                                          NaN   \n",
      "\n",
      "    program coverage of sth mda (%)_from_nis  \\\n",
      "1                                        NaN   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "5                                        NaN   \n",
      "8                                        NaN   \n",
      "..                                       ...   \n",
      "108                                      NaN   \n",
      "109                                      NaN   \n",
      "110                                      NaN   \n",
      "111                                      NaN   \n",
      "112                                      NaN   \n",
      "\n",
      "    program coverage of sth mda (%)_from_country  \\\n",
      "1                                            NaN   \n",
      "3                                            NaN   \n",
      "4                                            NaN   \n",
      "5                                            NaN   \n",
      "8                                            NaN   \n",
      "..                                           ...   \n",
      "108                                          NaN   \n",
      "109                                          NaN   \n",
      "110                                          NaN   \n",
      "111                                          NaN   \n",
      "112                                          NaN   \n",
      "\n",
      "    district treated for lf and ov with usaid funding_from_nis  \\\n",
      "1                                                  NaN           \n",
      "3                                                  NaN           \n",
      "4                                                  NaN           \n",
      "5                                                  NaN           \n",
      "8                                                  NaN           \n",
      "..                                                 ...           \n",
      "108                                                NaN           \n",
      "109                                                NaN           \n",
      "110                                                NaN           \n",
      "111                                                NaN           \n",
      "112                                                NaN           \n",
      "\n",
      "    district treated for lf and ov with usaid funding_from_country  \\\n",
      "1                                                  NaN               \n",
      "3                                                  NaN               \n",
      "4                                                  NaN               \n",
      "5                                                  NaN               \n",
      "8                                                  NaN               \n",
      "..                                                 ...               \n",
      "108                                                NaN               \n",
      "109                                                NaN               \n",
      "110                                                NaN               \n",
      "111                                                NaN               \n",
      "112                                                NaN               \n",
      "\n",
      "    district treated for lf and sth with usaid funding_from_nis  \\\n",
      "1                                                  NaN            \n",
      "3                                                  NaN            \n",
      "4                                                  NaN            \n",
      "5                                                  NaN            \n",
      "8                                                  NaN            \n",
      "..                                                 ...            \n",
      "108                                                NaN            \n",
      "109                                                NaN            \n",
      "110                                                NaN            \n",
      "111                                                NaN            \n",
      "112                                                NaN            \n",
      "\n",
      "    district treated for lf and sth with usaid funding_from_country  \n",
      "1                                                  NaN               \n",
      "3                                                  NaN               \n",
      "4                                                  NaN               \n",
      "5                                                  NaN               \n",
      "8                                                  NaN               \n",
      "..                                                 ...               \n",
      "108                                                NaN               \n",
      "109                                                NaN               \n",
      "110                                                NaN               \n",
      "111                                                NaN               \n",
      "112                                                NaN               \n",
      "\n",
      "[90 rows x 425 columns]\n"
     ]
    }
   ],
   "source": [
    "print(compare.all_mismatch())\n",
    "with open(summary_output, 'w', encoding='utf-8') as report_file:\n",
    "    report_file.write(compare.report(sample_count=1000000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Additions and Deletions to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_nis_new = compare.df1_unq_rows\n",
    "from_country_new = compare.df2_unq_rows\n",
    "\n",
    "from_nis_new.to_excel(additions_deletions, sheet_name=\"From NIS\", index = False)\n",
    "\n",
    "with pd.ExcelWriter(additions_deletions, mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "    from_country_new.to_excel(writer, sheet_name = \"From Country\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [event uid, organisation unit*, event date, latitude, longitude, status, review status, mda start date*, treatment end date of mda, fy, budgeted year*, mda status*, reason to postpone or cancel mda, specify \"other\" reason to postpone or cancel mda, disease data applies to: lf, disease data applies to: sth, disease data applies to: ov, disease data applies to: sch, disease data applies to: tr, country, region, usaid-funded?, usaid funding source, non-usaid funding source, non-usaid funding source: specify other, usaid supported implementing partner #1, usaid supported implementing partner #2, non-usaid supported implementing partner #1, non-usaid-supported implementing partner #1: specify other, non-usaid supported implementing partner #2, non-usaid-supported implementing partner #2: specify other, mda comments, lf- mda type, lf- plan for mda treatment, lf- mda event, lf- level of mda implementation, lf- implementation unit definition, lf- implementation unit definition: specify \"other\", lf- number of eligible persons targeted, lf- number of psac targeted, lf- number of sac targeted, lf- number of persons treated, lf- number of females treated, lf- number of males treated, lf- number of psac treated, lf- number of sac treated, lf- number of sub-districts treated, lf- number of sub-districts treated that achieved sufficient coverage, lf- name(s) of sub-district(s) with low coverage mda, if applicable, lf- distribution platform(s): house to house, lf- distribution platform(s): fixed post, lf- distribution platform(s): school, lf- distribution platform(s): other, lf- distribution platform(s)- other, lf- mop-up distribution platform(s): house to house, lf- mop-up distribution platform(s): fixed post, lf- mop-up distribution platform(s): school, lf- mop-up distribution platform(s): other, lf- mop-up distribution platform(s) - specify \"other\", lf- improvement(s) made to mda (where applicable), lf- primary cause of low coverage (where applicable), lf- description of cause(s) of low coverage (where applicable), lf- recommendation(s) for next mda (where applicable), lf- pre-populate sth?, lf- pre-populate ov?, lf- pre-populate sch?, lf- pre-populate tr?, sth- mda type, sth- plan for mda treatment, sth- mda event, sth- level of mda implementation, sth- implementation unit definition, sth- implementation unit definition: specify \"other\", sth- number of eligible persons targeted, sth- number of psac targeted, sth- number of sac targeted, sth- number of hra targeted, sth- number of wra targeted, sth- number of persons treated, sth- number of females treated, sth- number of males treated, sth- number of psac treated, sth- number of sac treated, sth- number of hra treated, sth- number of wra treated, sth- number of sub-districts treated, sth- number of sub-districts treated that achieved sufficient coverage, sth- name(s) of sub-district(s) with low coverage mda, if applicable, sth- distribution platform(s): house to house, sth- distribution platform(s): fixed post, sth- distribution platform(s): school, sth- distribution platform(s): other, sth- distribution platform(s) - other, sth- mop-up distribution platform(s): house to house, sth- mop-up distribution platform(s): fixed post, sth- mop-up distribution platform(s): school, sth- mop-up distribution platform(s) - specify \"other\", sth- mop-up distribution platform(s) - specify \"other\".1, sth- improvement(s) made to mda (where applicable), sth- primary cause of low coverage (where applicable), ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 213 columns]\n"
     ]
    }
   ],
   "source": [
    "print(compare.df2_unq_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
